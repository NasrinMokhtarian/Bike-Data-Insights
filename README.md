#Flight Price Prediction

##Batch Processing Project

Data Ingestion with dlt

ğŸ“Œ Project Overview

This project focuses on building a batch data pipeline for analyzing a flight booking dataset. The goal is to extract, transform, and load (ETL) the dataset using dlt, DuckDB, pandas, and BigQuery for further analysis in Looker Studio. The project follows best practices learned in the DataTalksClub Data Engineering Zoomcamp 2025.

ğŸ” Objectives

Automate batch data ingestion using dlt.

Store raw data in DuckDB.

Perform data transformations using pandas.

Load processed data into BigQuery for analysis.

Create SQL queries and dashboards to generate insights.

ğŸ“‚ Repository Structure

â”œâ”€â”€ data/                # Sample dataset (if applicable)

â”œâ”€â”€ ingestion/           # dlt ingestion scripts

â”œâ”€â”€ transformations/     # Data cleaning and transformation scripts

â”œâ”€â”€ sql_queries/         # SQL queries for analysis

â”œâ”€â”€ dashboards/          # Dashboards & reports

â”œâ”€â”€ README.md            # Project documentation

ğŸ“Š Dataset

Source: Flight Price Prediction dataset from Kaggle

Format: CSV

Fields: Airline, Date, Time, Price, Class (Economy/Business), Stops, etc.

Frequency: Static dataset (one-time load)

âš™ï¸ Technologies Used

dlt (data ingestion from Kaggle to DuckDB)

DuckDB (temporary storage & processing)

pandas (data transformation & cleaning)

BigQuery (data warehousing & querying)

Looker Studio (visualization & reporting)

ğŸ”„ Batch Processing Pipeline

Extract Data: dlt downloads the dataset from Kaggle.

Store Raw Data: Data is stored in DuckDB.

Transform Data: pandas cleans and processes the data (e.g., date formatting, price conversions, stop count normalization).

Load into BigQuery: Processed data is stored for querying.

Analyze & Visualize: SQL queries + Looker Studio dashboards for insights.
